{"paragraphs":[{"title":"Word count: RDD Way","text":"%spark2.spark\nval sc = spark.sparkContext\nval textFile = sc.textFile(\"/__dsets/textdata/big.txt\")\ntextFile.take(5)\nval counts = textFile.flatMap(line => line.split(\" \"))\n                 .map(word => (word, 1))\n                 .reduceByKey(_ + _)\ncounts.take(10)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611621_184788333","id":"20190306-170147_567785562","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6539"},{"title":"Word count: DataSet Way","text":"%spark2.spark\nval textFile = spark.read.textFile(\"/__dsets/textdata/big.txt\")\ntextFile.count()\ntextFile.first()\nval counts = textFile.flatMap(line => line.split(\" \")).\n                                groupByKey(identity).count()\ncounts.take(10)\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611633_192483311","id":"20190306-171608_296902312","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6540"},{"title":"Python: DataFrames only","text":"%spark2.pyspark\ntextFile = spark.read.text(\"/__dsets/textdata/big.txt\")\ntextFile\n\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611634_193637558","id":"20190306-173447_565203967","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6541"},{"title":"Python: Convert from DataFrame to RDD: we have RDD of Row objects first then convert Row objects to strings","text":"%spark2.pyspark\ntfrdd = textFile.rdd\nprint(tfrdd.first())\nstrRdd = tfrdd.flatMap(list)\nstrRdd.first()","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611635_193252809","id":"20190306-174505_2142293296","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6542"},{"title":"Scala: DataSet of Strings can be easily converted to RDD of Strings:","text":"%spark2.spark\nval textFile = spark.read.textFile(\"/__dsets/textdata/big.txt\")\nval tfrdd = textFile.rdd\ntfrdd.first()\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611636_191329065","id":"20190306-175309_308200865","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6543"},{"text":"%sh\nwget http://wolly.cs.smu.ca/tmp/drivers.csv\nwget http://wolly.cs.smu.ca/tmp/timesheet.csv\nhadoop fs -mkdir -p /dsets/trucks\nhadoop fs -put drivers.csv /dsets/trucks\nhadoop fs -put timesheet.csv /dsets/trucks\nhadoop fs -ls /dsets/trucks\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611637_190944316","id":"20190306-181403_1375015495","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6544"},{"title":"Create DataFrame from CSV with inferred schema","text":"%spark2.pyspark\ndrivers = spark.read.csv(\"/dsets/trucks/drivers.csv\", header=True, inferSchema = \"true\")\ntimesheet = spark.read.csv(\"/dsets/trucks/timesheet.csv\", header=True,  inferSchema = \"true\")\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1552681611639_191713813","id":"20190306-195833_837839964","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6545"},{"title":"Show Schema","text":"%spark2.pyspark\ndrivers.printSchema()\nprint(drivers.columns)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611640_189790069","id":"20190306-200324_330331687","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6546"},{"title":"Get first 2 Row objects","text":"%spark2.pyspark\ndrivers.take(2)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"lineNumbers":false,"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611641_189405320","id":"20190306-200404_1125827141","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6547"},{"title":"Print first 2 rows","text":"%spark2.pyspark\ndrivers.show(2)\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611642_190559567","id":"20190306-200613_1586406463","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6548"},{"title":"Show row count","text":"%spark2.pyspark\nprint(drivers.count())\nprint(timesheet.count())","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611643_190174818","id":"20190306-200721_1433192769","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6549"},{"title":"Show stats for each column","text":"%spark2.pyspark\ndrivers.describe().show()\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611645_187866324","id":"20190306-200823_1434106739","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6550"},{"title":"Select particular columns","text":"%spark2.pyspark\ndrivers.select('driverId','name').show(3)\ndrivers.select(drivers.columns[:2]).show(3)\ndriv = drivers.select('driverId','name')","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611645_187866324","id":"20190306-201111_1217789630","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6551"},{"title":"","text":"%spark2.pyspark\ntimesheet.show(2)\ntsheet = timesheet.select('driverId', 'hours-logged', 'miles-logged')\ntsheet.show(2)\ntimesheet.drop('week').show(2)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"lineNumbers":false,"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611646_189020571","id":"20190306-202524_622340310","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6552"},{"title":"Group by and Aggregate","text":"%spark2.pyspark\naggsheet = tsheet.groupby('driverId').agg({'hours-logged': 'sum', 'miles-logged': 'sum'})\naggsheet.show(2)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611646_189020571","id":"20190306-204645_2009142402","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6553"},{"title":"Join","text":"%spark2.pyspark\njoined = driv.join(aggsheet, [\"driverId\"], 'inner')\njoined.show(2)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611647_188635822","id":"20190306-205258_1689146874","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6554"},{"title":"Complete example","text":"%spark2.pyspark\ndrivers = spark.read.csv(\"/dsets/trucks/drivers.csv\", header=True, inferSchema = \"true\")\ntimesheet = spark.read.csv(\"/dsets/trucks/timesheet.csv\", header=True,  inferSchema = \"true\")\ndriv = drivers.select('driverId','name')\ntsheet = timesheet.select('driverId', 'hours-logged', 'miles-logged')\naggsheet = tsheet.groupby('driverId').agg({'hours-logged': 'sum', 'miles-logged': 'sum'})\njoined = driv.join(aggsheet, [\"driverId\"], 'inner')\njoined.show(2)\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611647_188635822","id":"20190306-201137_1775253947","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6555"},{"title":"Filtering","text":"%spark2.pyspark\njoined.filter(joined[\"driverId\"] < 13).show()\njoined.filter(joined.driverId < 13).filter(joined[\"name\"].rlike(\"^Paul.*\")).show()","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{"0":{"graph":{"mode":"table","height":344,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611648_272895831","id":"20190307-143435_2017416894","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6556"},{"title":"Rename columns","text":"%spark2.pyspark\njoined = joined.withColumnRenamed('sum(miles-logged)', 'miles_logged')\njoined.show(2)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611648_272895831","id":"20190306-200555_248439316","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6557"},{"title":"Order By","text":"%spark2.pyspark\njoined.orderBy(joined[\"driverId\"].asc()).show(3)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611649_272511082","id":"20190307-154027_1670866948","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6558"},{"title":"New column from existing ones","text":"%spark2.pyspark\njoined.withColumn('miles_and_hours', joined['miles_logged'] + joined['sum(hours-logged)']).show(3)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611649_272511082","id":"20190307-155118_2028774656","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6559"},{"title":"Transformations with regular expressions","text":"%spark2.pyspark\nfrom pyspark.sql.functions import *\njoined.withColumn(\"first_name\", regexp_replace('name', \"(.+) (.+)\",\"$1\")).show(3)","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611650_273665329","id":"20190315-201333_752829179","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6560"},{"title":"Exercise 1","text":"%spark2.pyspark\ntimesheet.printSchema()\n##How many weeks are logged?\n\n##What is the week number with the maximum value of ratio of the average miles logged to average hours logged?\n\n##Is it different from the week number with the maximum average of ratio of miles logged to hours logged?\n\n##(If time permits): Add an extra column to the drivers DataFrame - it should show the first letter of the first name and last name (e.g., Rommel Garcia -> R. Garcia)","dateUpdated":"2019-03-15T20:31:13+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- driverId: integer (nullable = true)\n |-- week: integer (nullable = true)\n |-- hours-logged: integer (nullable = true)\n |-- miles-logged: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1552681611652_271356836","id":"20190307-163718_2051885987","dateCreated":"2019-03-15T20:26:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:6563","user":"anonymous","dateFinished":"2019-03-15T20:31:14+0000","dateStarted":"2019-03-15T20:31:13+0000"},{"title":"Spark SQL: register tables first","text":"%spark2.pyspark\ndrivers = spark.read.csv(\"/dsets/trucks/drivers.csv\", header=True, inferSchema = \"true\")\ntimesheet = spark.read.csv(\"/dsets/trucks/timesheet.csv\", header=True,  inferSchema = \"true\")\ndrivers.createOrReplaceTempView('drivers')\ntimesheet.createOrReplaceTempView('timesheet')","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1552681611652_271356836","id":"20190307-172127_77042743","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6564"},{"text":"%spark2.pyspark\nspark.sql(\"select * from drivers\").show(2)\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611653_270972087","id":"20190311-163738_1164994041","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6565"},{"text":"%spark2.pyspark\ndf = spark.sql(\"select * from drivers\")\nprint(df)\ndf.printSchema()","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611654_272126334","id":"20190311-165033_1479620568","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6566"},{"title":"Example in Spark SQL","text":"%spark2.pyspark\nspark.sql(\"SELECT driverId,\\\n                    SUM(`hours-logged`) as hours, \\\n                    SUM(`miles-logged`) as miles \\\n                    FROM timesheet \\\n                    GROUP BY driverId\").createOrReplaceTempView('aggregated_ts');\n                    \nspark.sql(\"SELECT drivers.driverId,\\\n                    drivers.name,\\\n                    aggregated_ts.* \\\n                    from drivers JOIN aggregated_ts ON drivers.driverId == aggregated_ts.driverId\").show(2)\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611654_272126334","id":"20190311-165142_1511294184","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6567"},{"title":"Working with Parquet files: write to parquet","text":"%spark2.pyspark\ndrivers.write.parquet(\"/__dsets/drivers.parquet\")","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611650_273665329","id":"20190312-163649_745152868","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6561","focus":true},{"title":"Working with Parquet files: read from parquet","text":"%spark2.pyspark\ndrv_parq = spark.read.parquet(\"/__dsets/drivers.parquet\")\ndrv_parq.printSchema()\ndrivers.printSchema()\n","dateUpdated":"2019-03-15T20:40:40+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611651_273280580","id":"20190312-163726_728580149","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6562","focus":true},{"text":"%spark2.pyspark\nspark.sql(\"SELECT * FROM aggregated_ts\").write.csv(\"/__dsets/agg\")","dateUpdated":"2019-03-15T20:32:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"},"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1552681611660_268278845","id":"20190314-195435_2084270438","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6568","title":"Write a CSV file: first attempt"},{"text":"%sh\nhadoop fs -ls /__dsets/agg","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611661_267894096","id":"20190314-195749_1308303814","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6569"},{"text":"%sh\n#hadoop fs -cat /__dsets/agg/","dateUpdated":"2019-03-15T20:33:13+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611663_268663593","id":"20190315-003911_1217653563","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6570"},{"text":"%spark2.pyspark\nspark.sql(\"SELECT * FROM aggregated_ts\").coalesce(1)\\\n                                        .write.csv(\"/__dsets/agg1\")","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1552681611664_279051814","id":"20190315-004018_1203046565","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6571"},{"text":"%sh\nhadoop fs -ls /__dsets/agg1\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611665_278667065","id":"20190315-004126_251908388","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6572"},{"title":"Exercise 2","text":"%spark2.pyspark\nspark.sql(\"select * from drivers\").show(2)\n##How many different wage plans are in our dataset?\n\n##Compare wage plans: which one is more popular?\n\n##What about value of ratio of the average miles logged to average hours logged within the wage plans?\n\n##Is it different from average of ratio of miles logged to hours logged within the wage plans?\n\n##Save results as one CSV file\n\n##Which one is easier to work with: SQL API or DataFrame API?\n\n\n\n","dateUpdated":"2019-03-15T20:47:13+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611666_279821312","id":"20190312-152720_928532961","dateCreated":"2019-03-15T20:26:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6573","user":"anonymous","dateFinished":"2019-03-15T20:44:29+0000","dateStarted":"2019-03-15T20:44:27+0000"},{"title":"Work as with SQL tables in Zeppelin","text":"%sql\nSELECT * FROM drivers\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":true,"setting":{"pieChart":{}},"commonSetting":{},"keys":[{"name":"wage-plan","index":5,"aggr":"sum"}],"groups":[],"values":[{"name":"wage-plan","index":5,"aggr":"count"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611667_279436563","id":"20190311-165422_54446750","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6574"},{"text":"%spark2.pyspark\ndf = spark.sql(\"SELECT COUNT(certified) FROM drivers GROUP BY certified\").toPandas()\ndf.plot.bar();\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611668_277512818","id":"20190312-140727_2074045828","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6575"},{"text":"%spark2.pyspark\ndrivers.write.mode(\"overwrite\").saveAsTable(\"drivers\")","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1552681611669_277128069","id":"20190312-152805_2126208315","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6576"},{"text":"%sh\nhadoop fs -mkdir /__dsets/s_out\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","results":{},"enabled":true,"editorSetting":{"language":"sh","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611670_278282316","id":"20190312-171635_1732522104","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6577"},{"text":"%sh\n","dateUpdated":"2019-03-15T20:26:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1552681611671_277897567","id":"20190315-192013_1538262368","dateCreated":"2019-03-15T20:26:51+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:6578"}],"name":"SparkSQL2019","id":"2E6ZJV1S5","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}